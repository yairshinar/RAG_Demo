{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA Comparison: BERT-style Extractive vs RAG-style Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Proj\\RAG\\rag-demo-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Proj\\RAG\\rag-demo-env\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Proj\\RAG\\rag-demo-env\\Lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering, AutoModel, AutoModelForSeq2SeqLM\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example text and question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''ProductX is the latest widget released in 2024. It features improved battery life.\n",
    "To reset ProductX, hold the power button for 10 seconds until the LED blinks.\n",
    "Our support plans include Basic, Plus, and Enterprise tiers. ''' \n",
    "# context = [\n",
    "#     \"ProductX is the latest widget released in 2024. It features improved battery life.\",\n",
    "#     \"To reset ProductX, hold the power button for 10 seconds until the LED blinks.\",\n",
    "#     \"Our support plans include Basic, Plus, and Enterprise tiers, offering 24/7 support in higher tiers.\"\n",
    "# ]\n",
    "question = 'How many plans are there   ?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¶ Part 1: BERT-style extractive QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractive Answer: Basic, Plus, and Enterprise tiers\n"
     ]
    }
   ],
   "source": [
    "bert_qa = pipeline('question-answering', model='distilbert-base-cased-distilled-squad') \n",
    "bert_result = bert_qa(question=question, context=context) \n",
    "print(f\"Extractive Answer: {bert_result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŸ¢ Part 2: RAG-style semantic retrieval + generative QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model\\n\n",
    "embed_model_name = 'sentence-transformers/all-MiniLM-L6-v2' \n",
    "embed_tokenizer = AutoTokenizer.from_pretrained(embed_model_name) \n",
    "embed_model = AutoModel.from_pretrained(embed_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask): \n",
    "    token_embeddings = model_output[0]  \n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float() \n",
    "    return (token_embeddings * input_mask_expanded).sum(1) / input_mask_expanded.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(text): \n",
    "    tokens = embed_tokenizer([text], return_tensors='pt', padding=True, truncation=True) \n",
    "    with torch.no_grad(): \n",
    "        output = embed_model(**tokens) \n",
    "    return mean_pooling(output, tokens['attention_mask']).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query shape: (384,)\n",
      "sentences shape: (5, 384)\n",
      "Retrieved for RAG: Our support plans include Basic, Plus, and Enterprise tiers\n"
     ]
    }
   ],
   "source": [
    "# Split context into sentences\\n\n",
    "sentences = context.strip().split(\".\") \n",
    "sentence_embeddings = np.vstack([embed(s) for s in sentences]) \n",
    "query_embedding = embed(question)[0]\n",
    "print(\"query shape:\", query_embedding.shape)\n",
    "print(\"sentences shape:\", sentence_embeddings.shape)\n",
    "\n",
    "similarities = cosine_similarity([query_embedding], sentence_embeddings)[0]  \n",
    "best_idx = int(np.argmax(similarities)) \n",
    "retrieved = sentences[best_idx].strip() \n",
    "print(f\"Retrieved for RAG: {retrieved}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 384)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_embedding.shape\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Proj\\RAG\\rag-demo-env\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative Answer: three\n"
     ]
    }
   ],
   "source": [
    "# Generation model\\n\n",
    "gen_pipeline = pipeline('text2text-generation', model='google/flan-t5-base') \n",
    "prompt = f\"Context: {retrieved} Question: {question} Answer:\" \n",
    "gen_result = gen_pipeline(prompt, max_length=100)[0]['generated_text'] \n",
    "print(f\"Generative Answer: {gen_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-demo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
